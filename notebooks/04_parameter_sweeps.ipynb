{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Sweeps and Optimization\n",
    "\n",
    "This notebook demonstrates how to use the `run_sweep` method to systematically test different agent configurations and find optimal parameters.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `run_sweep` method enables:\n",
    "- **Systematic exploration**: Test multiple parameter combinations\n",
    "- **Fair comparison**: Same seeds ensure consistent evaluation\n",
    "- **Flexible tracking**: Use any tracker to collect data\n",
    "- **Policy factories**: Generate policies from parameter dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch device: MPS (Apple Silicon)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from experiments import MultiAgentCodenamesExperiment, SummaryTracker, EpisodeTracker\n",
    "from envs.word_batch_env import WordBatchEnv\n",
    "from agents.spymaster import RandomSpymaster, EmbeddingSpymaster, SpymasterParams\n",
    "from agents.guesser import RandomGuesser, EmbeddingGuesser, GuesserParams\n",
    "\n",
    "# Seaborn style for better plots\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Parameter Sweep\n",
    "\n",
    "Let's sweep over the `n_candidate_clues` parameter for embedding spymasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading spymaster model: all-MiniLM-L6-v2 on mps\n",
      "Embedding agents available!\n"
     ]
    }
   ],
   "source": [
    "# Check if embedding agents are available\n",
    "try:\n",
    "    test_spy = EmbeddingSpymaster(team=\"red\", params=SpymasterParams())\n",
    "    EMBEDDINGS_AVAILABLE = True\n",
    "    print(\"Embedding agents available!\")\n",
    "except RuntimeError:\n",
    "    EMBEDDINGS_AVAILABLE = False\n",
    "    print(\"Embedding agents not available. Install sentence-transformers.\")\n",
    "    print(\"Falling back to random agents for demonstration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running parameter sweep...\n",
      "\n",
      "Configuration 1/5: {'n_candidate_clues': 5}\n",
      "Using device: mps\n",
      "Using device: mps\n",
      "Loading guesser model: all-MiniLM-L6-v2 on mps\n",
      "Using device: mps\n",
      "Using device: mps\n",
      "Completed 8/50 games\n",
      "Completed 16/50 games\n",
      "Completed 24/50 games\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     32\u001b[39m     param_grid = [\n\u001b[32m     33\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mn_candidate_clues\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m},\n\u001b[32m     34\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mn_candidate_clues\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m10\u001b[39m},\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mn_candidate_clues\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m100\u001b[39m},\n\u001b[32m     38\u001b[39m     ]\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning parameter sweep...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     sweep_results = \u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sweep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_policies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_games_per_config\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSweep complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/codenames-bot/experiments/multi_agent_experiment.py:240\u001b[39m, in \u001b[36mMultiAgentCodenamesExperiment.run_sweep\u001b[39m\u001b[34m(self, policy_factory, param_grid, n_games_per_config, tracker_factory, seed, verbose)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;66;03m# Run games with this configuration\u001b[39;00m\n\u001b[32m    239\u001b[39m config_seed = seed + i * \u001b[32m10000\u001b[39m  \u001b[38;5;66;03m# Ensure different seeds per config\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_games\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolicy_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_games\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_games_per_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[32m    249\u001b[39m sweep_results.append({\n\u001b[32m    250\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: params,\n\u001b[32m    251\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m: results,\n\u001b[32m    252\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: config_seed\n\u001b[32m    253\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/codenames-bot/experiments/multi_agent_experiment.py:137\u001b[39m, in \u001b[36mMultiAgentCodenamesExperiment.run_games\u001b[39m\u001b[34m(self, policy_map, n_games, tracker, seed, verbose)\u001b[39m\n\u001b[32m    135\u001b[39m actions_dict = {}\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent_id, policy \u001b[38;5;129;01min\u001b[39;00m policy_map.items():\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     actions_dict[agent_id] = \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Step environment\u001b[39;00m\n\u001b[32m    140\u001b[39m obs_dict, rewards_dict, dones_dict, infos_dict = env.step(actions_dict)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mmake_policies.<locals>.<lambda>\u001b[39m\u001b[34m(obs)\u001b[39m\n\u001b[32m     21\u001b[39m red_guess = EmbeddingGuesser(team=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m, params=GuesserParams(seed=\u001b[32m44\u001b[39m))\n\u001b[32m     22\u001b[39m blue_guess = EmbeddingGuesser(team=\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m, params=GuesserParams(seed=\u001b[32m45\u001b[39m))\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mred_spy\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m obs: red_spy.get_clue(obs),\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mred_guess\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m obs: red_guess.get_guess(obs),\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mblue_spy\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m obs: blue_spy.get_clue(obs),\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mblue_guess\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m obs: \u001b[43mblue_guess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_guess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     29\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/codenames-bot/agents/guesser/embedding_guesser.py:130\u001b[39m, in \u001b[36mEmbeddingGuesser.get_guess\u001b[39m\u001b[34m(self, obs)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_text) == \u001b[32m0\u001b[39m:\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mtile_index\u001b[39m\u001b[33m\"\u001b[39m: np.zeros(batch_size, dtype=np.int32)}\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m all_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m all_embeddings = torch.from_numpy(all_embeddings).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    133\u001b[39m clue_embeddings = all_embeddings[:\u001b[38;5;28mlen\u001b[39m(clue_unique)]  \u001b[38;5;66;03m# [n_clues, D]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/sentence_transformers/models/Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:1000\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    998\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1014\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:650\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    646\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    648\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:558\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    548\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    556\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    557\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    567\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/py313/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Create experiment\n",
    "exp = MultiAgentCodenamesExperiment(\n",
    "    env_factory=lambda seed: WordBatchEnv(batch_size=8, seed=seed),\n",
    "    max_turns=50\n",
    ")\n",
    "\n",
    "if EMBEDDINGS_AVAILABLE:\n",
    "    # Define policy factory\n",
    "    def make_policies(params):\n",
    "        \"\"\"Create policy map from parameters.\"\"\"\n",
    "        n_candidates = params['n_candidate_clues']\n",
    "        \n",
    "        red_spy = EmbeddingSpymaster(\n",
    "            team=\"red\",\n",
    "            params=SpymasterParams(n_candidate_clues=n_candidates, seed=42)\n",
    "        )\n",
    "        blue_spy = EmbeddingSpymaster(\n",
    "            team=\"blue\",\n",
    "            params=SpymasterParams(n_candidate_clues=n_candidates, seed=43)\n",
    "        )\n",
    "        red_guess = EmbeddingGuesser(team=\"red\", params=GuesserParams(seed=44))\n",
    "        blue_guess = EmbeddingGuesser(team=\"blue\", params=GuesserParams(seed=45))\n",
    "        \n",
    "        return {\n",
    "            \"red_spy\": lambda obs: red_spy.get_clue(obs),\n",
    "            \"red_guess\": lambda obs: red_guess.get_guess(obs),\n",
    "            \"blue_spy\": lambda obs: blue_spy.get_clue(obs),\n",
    "            \"blue_guess\": lambda obs: blue_guess.get_guess(obs),\n",
    "        }\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = [\n",
    "        {\"n_candidate_clues\": 5},\n",
    "        {\"n_candidate_clues\": 10},\n",
    "        {\"n_candidate_clues\": 20},\n",
    "        {\"n_candidate_clues\": 50},\n",
    "        {\"n_candidate_clues\": 100},\n",
    "    ]\n",
    "    \n",
    "    print(\"Running parameter sweep...\")\n",
    "    sweep_results = exp.run_sweep(\n",
    "        policy_factory=make_policies,\n",
    "        param_grid=param_grid,\n",
    "        n_games_per_config=50,\n",
    "        seed=42,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSweep complete!\")\n",
    "else:\n",
    "    print(\"Skipping embedding sweep - using random agents for demonstration\")\n",
    "    \n",
    "    def make_random_policies(params):\n",
    "        seed_offset = params.get('seed_offset', 0)\n",
    "        return {\n",
    "            \"red_spy\": lambda obs: RandomSpymaster(team=\"red\", params=SpymasterParams(seed=42+seed_offset)).get_clue(obs),\n",
    "            \"red_guess\": lambda obs: RandomGuesser(team=\"red\", params=GuesserParams(seed=43+seed_offset)).get_guess(obs),\n",
    "            \"blue_spy\": lambda obs: RandomSpymaster(team=\"blue\", params=SpymasterParams(seed=44+seed_offset)).get_clue(obs),\n",
    "            \"blue_guess\": lambda obs: RandomGuesser(team=\"blue\", params=GuesserParams(seed=45+seed_offset)).get_guess(obs),\n",
    "        }\n",
    "    \n",
    "    param_grid = [{\"seed_offset\": i} for i in range(5)]\n",
    "    sweep_results = exp.run_sweep(\n",
    "        policy_factory=make_random_policies,\n",
    "        param_grid=param_grid,\n",
    "        n_games_per_config=30,\n",
    "        seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyzing Sweep Results\n",
    "\n",
    "The sweep returns a list of dicts with params, results, and seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n_candidate_clues  red_win_rate  blue_win_rate  avg_turns  red_spy_reward  red_guess_reward\n",
      "                 5      0.500000       0.500000   6.803571        0.000000         -7.053571\n",
      "                10      0.535714       0.464286   7.821429        0.017857         -6.589286\n",
      "                20      0.553571       0.446429   6.767857       -0.017857         -7.642857\n",
      "                50      0.446429       0.553571   8.178571        0.017857         -6.321429\n",
      "               100      0.482143       0.517857   8.857143        0.000000         -8.107143\n"
     ]
    }
   ],
   "source": [
    "# Extract data into DataFrame for easy analysis\n",
    "if EMBEDDINGS_AVAILABLE:\n",
    "    sweep_data = []\n",
    "    for result in sweep_results:\n",
    "        row = {\n",
    "            'n_candidate_clues': result['params']['n_candidate_clues'],\n",
    "            'red_win_rate': result['results']['red_win_rate'],\n",
    "            'blue_win_rate': result['results']['blue_win_rate'],\n",
    "            'avg_turns': result['results']['avg_turns'],\n",
    "            'red_spy_reward': result['results']['rewards_per_agent']['red_spy'],\n",
    "            'red_guess_reward': result['results']['rewards_per_agent']['red_guess'],\n",
    "        }\n",
    "        sweep_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(sweep_data)\n",
    "    print(df.to_string(index=False))\n",
    "else:\n",
    "    # Random agents - just show structure\n",
    "    print(\"Sweep results structure:\")\n",
    "    print(f\"Number of configs tested: {len(sweep_results)}\")\n",
    "    print(f\"\\nExample result:\")\n",
    "    print(f\"  Params: {sweep_results[0]['params']}\")\n",
    "    print(f\"  Red win rate: {sweep_results[0]['results']['red_win_rate']:.2%}\")\n",
    "    print(f\"  Avg turns: {sweep_results[0]['results']['avg_turns']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMBEDDINGS_AVAILABLE:\n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Win rate vs n_candidates\n",
    "    axes[0].plot(df['n_candidate_clues'], df['red_win_rate'], 'o-', label='Red', color='red')\n",
    "    axes[0].plot(df['n_candidate_clues'], df['blue_win_rate'], 'o-', label='Blue', color='blue')\n",
    "    axes[0].set_xlabel('Number of Candidate Clues')\n",
    "    axes[0].set_ylabel('Win Rate')\n",
    "    axes[0].set_title('Win Rate vs Candidate Clues')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Average turns vs n_candidates\n",
    "    axes[1].plot(df['n_candidate_clues'], df['avg_turns'], 'o-', color='green')\n",
    "    axes[1].set_xlabel('Number of Candidate Clues')\n",
    "    axes[1].set_ylabel('Average Turns')\n",
    "    axes[1].set_title('Game Length vs Candidate Clues')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rewards vs n_candidates\n",
    "    axes[2].plot(df['n_candidate_clues'], df['red_spy_reward'], 'o-', label='Spymaster', color='darkred')\n",
    "    axes[2].plot(df['n_candidate_clues'], df['red_guess_reward'], 'o-', label='Guesser', color='coral')\n",
    "    axes[2].set_xlabel('Number of Candidate Clues')\n",
    "    axes[2].set_ylabel('Red Team Avg Reward')\n",
    "    axes[2].set_title('Reward vs Candidate Clues')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find optimal\n",
    "    best_idx = df['red_spy_reward'].idxmax()\n",
    "    print(f\"\\nBest configuration:\")\n",
    "    print(f\"  n_candidate_clues: {df.iloc[best_idx]['n_candidate_clues']:.0f}\")\n",
    "    print(f\"  Red win rate: {df.iloc[best_idx]['red_win_rate']:.2%}\")\n",
    "    print(f\"  Avg reward: {df.iloc[best_idx]['red_spy_reward']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Dimensional Parameter Sweep\n",
    "\n",
    "Let's sweep over multiple parameters simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMBEDDINGS_AVAILABLE:\n",
    "    # Define 2D parameter grid\n",
    "    def make_policies_2d(params):\n",
    "        n_candidates = params['n_candidate_clues']\n",
    "        risk_tolerance = params['risk_tolerance']\n",
    "        \n",
    "        red_spy = EmbeddingSpymaster(\n",
    "            team=\"red\",\n",
    "            params=SpymasterParams(\n",
    "                n_candidate_clues=n_candidates,\n",
    "                risk_tolerance=risk_tolerance,\n",
    "                seed=42\n",
    "            )\n",
    "        )\n",
    "        blue_spy = EmbeddingSpymaster(\n",
    "            team=\"blue\",\n",
    "            params=SpymasterParams(\n",
    "                n_candidate_clues=n_candidates,\n",
    "                risk_tolerance=risk_tolerance,\n",
    "                seed=43\n",
    "            )\n",
    "        )\n",
    "        red_guess = EmbeddingGuesser(team=\"red\", params=GuesserParams(seed=44))\n",
    "        blue_guess = EmbeddingGuesser(team=\"blue\", params=GuesserParams(seed=45))\n",
    "        \n",
    "        return {\n",
    "            \"red_spy\": lambda obs: red_spy.get_clue(obs),\n",
    "            \"red_guess\": lambda obs: red_guess.get_guess(obs),\n",
    "            \"blue_spy\": lambda obs: blue_spy.get_clue(obs),\n",
    "            \"blue_guess\": lambda obs: blue_guess.get_guess(obs),\n",
    "        }\n",
    "    \n",
    "    # Grid search\n",
    "    param_grid_2d = []\n",
    "    for n_candidates in [10, 20, 50]:\n",
    "        for risk in [1.0, 2.0, 3.0]:\n",
    "            param_grid_2d.append({\n",
    "                'n_candidate_clues': n_candidates,\n",
    "                'risk_tolerance': risk\n",
    "            })\n",
    "    \n",
    "    print(f\"Testing {len(param_grid_2d)} configurations...\")\n",
    "    sweep_2d_results = exp.run_sweep(\n",
    "        policy_factory=make_policies_2d,\n",
    "        param_grid=param_grid_2d,\n",
    "        n_games_per_config=30,\n",
    "        seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Extract to DataFrame\n",
    "    sweep_2d_data = []\n",
    "    for result in sweep_2d_results:\n",
    "        row = {\n",
    "            'n_candidate_clues': result['params']['n_candidate_clues'],\n",
    "            'risk_tolerance': result['params']['risk_tolerance'],\n",
    "            'red_win_rate': result['results']['red_win_rate'],\n",
    "            'avg_turns': result['results']['avg_turns'],\n",
    "            'red_spy_reward': result['results']['rewards_per_agent']['red_spy'],\n",
    "        }\n",
    "        sweep_2d_data.append(row)\n",
    "    \n",
    "    df_2d = pd.DataFrame(sweep_2d_data)\n",
    "    print(\"\\n2D Sweep Results:\")\n",
    "    print(df_2d.to_string(index=False))\n",
    "else:\n",
    "    print(\"Skipping 2D sweep (requires embedding agents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMBEDDINGS_AVAILABLE:\n",
    "    # Create heatmap\n",
    "    pivot_win_rate = df_2d.pivot(index='risk_tolerance', columns='n_candidate_clues', values='red_win_rate')\n",
    "    pivot_reward = df_2d.pivot(index='risk_tolerance', columns='n_candidate_clues', values='red_spy_reward')\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Win rate heatmap\n",
    "    sns.heatmap(pivot_win_rate, annot=True, fmt='.2f', cmap='RdYlGn', ax=axes[0], cbar_kws={'label': 'Win Rate'})\n",
    "    axes[0].set_title('Red Win Rate')\n",
    "    axes[0].set_xlabel('Number of Candidate Clues')\n",
    "    axes[0].set_ylabel('Risk Tolerance')\n",
    "    \n",
    "    # Reward heatmap\n",
    "    sns.heatmap(pivot_reward, annot=True, fmt='.2f', cmap='viridis', ax=axes[1], cbar_kws={'label': 'Avg Reward'})\n",
    "    axes[1].set_title('Red Spymaster Avg Reward')\n",
    "    axes[1].set_xlabel('Number of Candidate Clues')\n",
    "    axes[1].set_ylabel('Risk Tolerance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find optimal combination\n",
    "    best_idx = df_2d['red_spy_reward'].idxmax()\n",
    "    print(f\"\\nOptimal configuration:\")\n",
    "    print(f\"  n_candidate_clues: {df_2d.iloc[best_idx]['n_candidate_clues']:.0f}\")\n",
    "    print(f\"  risk_tolerance: {df_2d.iloc[best_idx]['risk_tolerance']:.1f}\")\n",
    "    print(f\"  Red win rate: {df_2d.iloc[best_idx]['red_win_rate']:.2%}\")\n",
    "    print(f\"  Avg reward: {df_2d.iloc[best_idx]['red_spy_reward']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Asymmetric Agent Comparison\n",
    "\n",
    "Compare different agent types (e.g., random vs embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMBEDDINGS_AVAILABLE:\n",
    "    # Test different team compositions\n",
    "    def make_asymmetric_policies(params):\n",
    "        red_type = params['red_type']\n",
    "        blue_type = params['blue_type']\n",
    "        \n",
    "        # Create red agents\n",
    "        if red_type == 'random':\n",
    "            red_spy = RandomSpymaster(team=\"red\")\n",
    "            red_guess = RandomGuesser(team=\"red\")\n",
    "        else:  # embedding\n",
    "            red_spy = EmbeddingSpymaster(team=\"red\", params=SpymasterParams(n_candidate_clues=20, seed=42))\n",
    "            red_guess = EmbeddingGuesser(team=\"red\", params=GuesserParams(seed=43))\n",
    "        \n",
    "        # Create blue agents\n",
    "        if blue_type == 'random':\n",
    "            blue_spy = RandomSpymaster(team=\"blue\")\n",
    "            blue_guess = RandomGuesser(team=\"blue\")\n",
    "        else:  # embedding\n",
    "            blue_spy = EmbeddingSpymaster(team=\"blue\", params=SpymasterParams(n_candidate_clues=20, seed=44))\n",
    "            blue_guess = EmbeddingGuesser(team=\"blue\", params=GuesserParams(seed=45))\n",
    "        \n",
    "        return {\n",
    "            \"red_spy\": lambda obs: red_spy.get_clue(obs),\n",
    "            \"red_guess\": lambda obs: red_guess.get_guess(obs),\n",
    "            \"blue_spy\": lambda obs: blue_spy.get_clue(obs),\n",
    "            \"blue_guess\": lambda obs: blue_guess.get_guess(obs),\n",
    "        }\n",
    "    \n",
    "    # Test all combinations\n",
    "    asymmetric_grid = [\n",
    "        {'red_type': 'random', 'blue_type': 'random'},\n",
    "        {'red_type': 'random', 'blue_type': 'embedding'},\n",
    "        {'red_type': 'embedding', 'blue_type': 'random'},\n",
    "        {'red_type': 'embedding', 'blue_type': 'embedding'},\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing asymmetric matchups...\")\n",
    "    asymmetric_results = exp.run_sweep(\n",
    "        policy_factory=make_asymmetric_policies,\n",
    "        param_grid=asymmetric_grid,\n",
    "        n_games_per_config=50,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n=== Asymmetric Matchup Results ===\")\n",
    "    for result in asymmetric_results:\n",
    "        red_type = result['params']['red_type']\n",
    "        blue_type = result['params']['blue_type']\n",
    "        red_wr = result['results']['red_win_rate']\n",
    "        blue_wr = result['results']['blue_win_rate']\n",
    "        avg_turns = result['results']['avg_turns']\n",
    "        \n",
    "        print(f\"\\n{red_type:10s} vs {blue_type:10s}\")\n",
    "        print(f\"  Red win rate:  {red_wr:.2%}\")\n",
    "        print(f\"  Blue win rate: {blue_wr:.2%}\")\n",
    "        print(f\"  Draw rate:     {(1 - red_wr - blue_wr):.2%}\")\n",
    "        print(f\"  Avg turns:     {avg_turns:.1f}\")\n",
    "else:\n",
    "    print(\"Skipping asymmetric comparison (requires embedding agents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Significance Testing\n",
    "\n",
    "Use episode-level data to assess if differences are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMBEDDINGS_AVAILABLE:\n",
    "    from scipy import stats\n",
    "    \n",
    "    # Compare two specific configurations with episode tracker\n",
    "    config_a = {'n_candidate_clues': 10}\n",
    "    config_b = {'n_candidate_clues': 50}\n",
    "    \n",
    "    # Run with episode tracker\n",
    "    tracker_a = EpisodeTracker()\n",
    "    exp.run_games(\n",
    "        policy_map=make_policies(config_a),\n",
    "        n_games=100,\n",
    "        tracker=tracker_a,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    tracker_b = EpisodeTracker()\n",
    "    exp.run_games(\n",
    "        policy_map=make_policies(config_b),\n",
    "        n_games=100,\n",
    "        tracker=tracker_b,\n",
    "        seed=42  # Same seed for paired comparison\n",
    "    )\n",
    "    \n",
    "    # Extract rewards\n",
    "    rewards_a = [ep['total_rewards']['red_spy'] for ep in tracker_a.get_results()]\n",
    "    rewards_b = [ep['total_rewards']['red_spy'] for ep in tracker_b.get_results()]\n",
    "    \n",
    "    # Paired t-test (same seeds = paired data)\n",
    "    t_stat, p_value = stats.ttest_rel(rewards_a, rewards_b)\n",
    "    \n",
    "    print(f\"Configuration A (n_candidates={config_a['n_candidate_clues']}):\")\n",
    "    print(f\"  Mean reward: {np.mean(rewards_a):.2f}  {np.std(rewards_a):.2f}\")\n",
    "    \n",
    "    print(f\"\\nConfiguration B (n_candidates={config_b['n_candidate_clues']}):\")\n",
    "    print(f\"  Mean reward: {np.mean(rewards_b):.2f}  {np.std(rewards_b):.2f}\")\n",
    "    \n",
    "    print(f\"\\nPaired t-test:\")\n",
    "    print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"  p-value: {p_value:.4f}\")\n",
    "    print(f\"  Significant (p < 0.05): {p_value < 0.05}\")\n",
    "    \n",
    "    # Plot distributions\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].hist(rewards_a, bins=20, alpha=0.5, label=f'A (n={config_a[\"n_candidate_clues\"]})', color='blue')\n",
    "    axes[0].hist(rewards_b, bins=20, alpha=0.5, label=f'B (n={config_b[\"n_candidate_clues\"]})', color='red')\n",
    "    axes[0].axvline(np.mean(rewards_a), color='blue', linestyle='--')\n",
    "    axes[0].axvline(np.mean(rewards_b), color='red', linestyle='--')\n",
    "    axes[0].set_xlabel('Episode Reward')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].set_title('Reward Distributions')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Paired differences\n",
    "    differences = np.array(rewards_b) - np.array(rewards_a)\n",
    "    axes[1].hist(differences, bins=20, edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvline(0, color='red', linestyle='--', label='No difference')\n",
    "    axes[1].axvline(np.mean(differences), color='green', linestyle='--', label=f'Mean diff: {np.mean(differences):.2f}')\n",
    "    axes[1].set_xlabel('Reward Difference (B - A)')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title('Paired Differences')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping significance testing (requires embedding agents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and Loading Results\n",
    "\n",
    "Save sweep results for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if EMBEDDINGS_AVAILABLE:\n",
    "    # Save sweep results\n",
    "    def save_sweep_results(results, filename):\n",
    "        \"\"\"Save sweep results to JSON.\"\"\"\n",
    "        # Convert numpy types to native Python types\n",
    "        serializable_results = []\n",
    "        for result in results:\n",
    "            serializable = {\n",
    "                'params': result['params'],\n",
    "                'seed': int(result['seed']),\n",
    "                'results': {\n",
    "                    'total_games': int(result['results']['total_games']),\n",
    "                    'red_win_rate': float(result['results']['red_win_rate']),\n",
    "                    'blue_win_rate': float(result['results']['blue_win_rate']),\n",
    "                    'avg_turns': float(result['results']['avg_turns']),\n",
    "                    'rewards_per_agent': {\n",
    "                        k: float(v) for k, v in result['results']['rewards_per_agent'].items()\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            serializable_results.append(serializable)\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "        \n",
    "        print(f\"Saved results to {filename}\")\n",
    "    \n",
    "    # Save results\n",
    "    save_sweep_results(sweep_results, 'sweep_results.json')\n",
    "    \n",
    "    # Load results\n",
    "    def load_sweep_results(filename):\n",
    "        \"\"\"Load sweep results from JSON.\"\"\"\n",
    "        with open(filename, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    loaded_results = load_sweep_results('sweep_results.json')\n",
    "    print(f\"\\nLoaded {len(loaded_results)} configurations\")\n",
    "else:\n",
    "    print(\"Skipping save/load (no sweep results available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You now know how to:\n",
    "- Use `run_sweep` for systematic parameter exploration\n",
    "- Analyze and visualize sweep results\n",
    "- Perform multi-dimensional parameter sweeps\n",
    "- Compare asymmetric agent matchups\n",
    "- Test statistical significance of differences\n",
    "- Save and load results for reproducibility\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Implement more sophisticated optimization (Bayesian optimization, evolutionary strategies)\n",
    "- Train RL agents using the insights from parameter sweeps\n",
    "- Build ensemble policies that combine multiple configurations\n",
    "- Analyze failure modes and edge cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
